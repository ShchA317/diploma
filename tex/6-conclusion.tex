\addcontentsline{toc}{section}{\protect\numberline{}ЗАКЛЮЧЕНИЕ}
\section*{\centering ЗАКЛЮЧЕНИЕ}

В ходе данной работы была спроектирована и реализована программа для прогнозирования нагрузки на диск со стороны 
системы управления базами данных PostgreSQL с целью последующего анализа производительности и обеспечения обоснованного 
выбора аппаратных и программных решений для хранения и работы с большими объемами данных. В процессе выполнения работы 
были проанализированы особенности организации файловой структуры PostgreSQL, изучены принципы функционирования системы 
хранения данных, механизмы обращения к файлам и их влияние на нагрузку ввода-вывода.

Целью разработки являлось создание инструмента, который позволял бы на основании характеристик целевой базы данных 
(размера файлов, предполагаемой активности, паттернов доступа) оценить потенциальную нагрузку на диск, представить её 
в разрезе различных вариантов использования кэша и параметров работы PostgreSQL, а также дать возможность разработчикам 
и администраторам баз данных принимать решения о масштабировании, резервировании ресурсов или оптимизации работы СУБД.

В результате, была реализована программа, формирующая детализированные прогнозы по каждому файлу хранения 
(основные файлы таблиц, индексы, TOAST, вспомогательные файлы), с учётом предполагаемого числа операций чтения и записи, 
сценариев уровня попадания в кэш (cache hit ratio) и оценивающая I/O-нагрузку по таким показателям, как количество 
операций (iops) и пропускная способность (throughput) для различных режимов работы. Программа генерирует структурированный 
и наглядный результат, удобный для последующего анализа и интеграции в документы проектирования или технические отчёты.

\textbf{Практическая ценность работы}
Разработанный инструмент предоставляет удобный способ быстрой оценки дисковой нагрузки при проектировании архитектуры 
информационной системы на базе PostgreSQL. Программа позволяет без необходимости проведения трудоёмких полноценных 
нагрузочных испытаний получить первые ориентировочные цифры: объём ожидаемых обращений к файловой системе, пропускную 
способность, зависимость этих величин от параметров кэширования. Это существенно снижает риски при проектировании, 
упрощает выбор аппаратных решений (тип и объём дисков, организация хранения, резервы под разрастание БД) и формирует 
базу для последующего более точного тестирования и калибровки. Полученные с помощью данного инструмента оценки могут 
использоваться для подготовки технических заданий, согласования бюджета на инфраструктуру, сравнения разных вариантов 
партицирования или индексирования, а также для планирования процедур обслуживания и резервного копирования.

Особенно эффективным представляется применение такой программы на этапах пилотирования проектов, где реальных данных 
еще недостаточно, а сценарии обращения к БД можно только приблизительно оценить. В таких ситуациях верификация 
проектных решений с помощью табличной “прогнозной” модели оказывается не только оправданной, но и позволяет избежать 
выбора заведомо неэффективных стратегий работы с СУБД.

\textbf{Ограничения и риски}
При всей полезности предложенного решения необходимо честно отметить ряд существенных ограничений, которые были 
подробно рассмотрены в соответствующем разделе. Наиболее значимым из них на текущем этапе развития программы является 
упрощение самой модели нагрузки: не учитываются операции UPDATE и DELETE, а также связанные с ними активности 
autovacuum и процессов обслуживания таблиц (reindex, анализ, переупаковка и пр.). Помимо этого, в расчетах полностью 
отсутствует влияние операций логирования, которые в PostgreSQL всегда сопровождают запись в таблицы и могут составлять 
значительную часть I/O-нагрузки.

Еще одной из сложностей является влияние механизмов кэширования как на уровне PostgreSQL, так и со стороны операционной 
системы и аппаратных буферов контроллеров и дисков: реальная нагрузка на устройство может быть существенно ниже или 
выше расчетной в зависимости от особенностей рабочей среды, типа используемой СОСД или гипервизора, физических 
характеристик используемых носителей и др. 
В ходе апробации отмечено, что при ряде тестов расхождение между прогнозной и измеренной нагрузкой может быть весьма 
значительным — это связано как с невозможностью точно угадать реальную структуру обращений к данным, так и с 
поведением внутренних оптимизаторов PostgreSQL, а также непредсказуемым влиянием фоновых процессов.

Вместе с тем автор считает, что предлагаемый подход сохраняет свою ценность, так как получаемые прогнозные данные 
позволяют выстраивать работу с учетом заведомых рисков: если по расчету нагрузка подходит вплотную к предельным 
значениям устройств или инфраструктуры, это сигнал о необходимости закладывать дополнительные резервы, либо 
пересматривать и оптимизировать архитектуру информационной системы до начала эксплуатации и насыщения реальными данными.

\textbf{Основные результаты и перспективы развития}
По итогам работы можно выделить основное достижение — разработан удобный в использовании и расширяемый инструмент 
для прогнозирования дисковой нагрузки, наглядно отображающий вклад каждого компонента хранилища и 
различных сценариев работы. Программа полностью отделена от специфики аппаратной платформы либо специализированных 
настроек и может быть использована как отправная точка в различных проектах, с возможностью адаптации под конкретные 
требования бизнеса и инфраструктуры.

Программа построена на гибкой модели ввода исходных данных и поддерживает расширение спектра анализируемых файлов 
и сценариев работы; результаты выводятся в формате, пригодном для коммуникации между разработчиками, архитекторами 
и обслуживающим персоналом.

Важное направление для дальнейшего развития — реализация более точной модели, учитывающей операции обновления и удаления, 
корректно моделирующей нагрузки от autovacuum и VACUUM FULL, анализирующей влияние WAL (журнала предзаписи) 
и фоновых процессов планирования, а также интеграция результатов реальных нагрузочных тестов для калибровки 
коэффициентов и уточнения входных данных. Следующим логичным шагом могла бы стать интеграция с мониторинговыми 
инструментами, что позволит автоматически сравнивать прогноз и реальные метрики, на лету корректируя модель 
под конкретную производственную систему.

Кроме этого, в перспективе рассматривается возможность автоматизированного формирования рекомендаций по оптимизации 
конфигурации PostgreSQL на основании полученных прогнозов, а также генерация предложений по поэтапному переходу 
на масштабируемые решения (например, sharding, распределенное хранение и др.) при превышении расчетной нагрузки.

\textbf{Заключительное слово}
В заключение стоит подчеркнуть, что поставленная задача создания инструмента для прогноза нагрузки на диск в рамках 
эксплуатации PostgreSQL актуальна как для организаций, разворачивающих новые масштабные ИС с нуля, так и для случаев 
миграции или реорганизации уже существующих проектов. Предложенная модель не подменяет собой полноценных нагрузочных 
тестов и не претендует на абсолютную точность, но позволяет существенно повысить осознанность при проектировании, 
выявить “узкие” места задолго до появления производственных проблем и сэкономить ресурсы на этапе экспериментов и проектирования.

В ходе выполнения данной работы сформирован задел для дальнейших исследований в области автоматизации процессов 
проектирования и сопровождения баз данных, повышения прозрачности и воспроизводимости процессов оценки нагрузки 
и в целом снижения издержек на поддержку и масштабирование корпоративных информационных систем.

В заключение отметим, что как для теоретического, так и для прикладного анализа работы PostgreSQL и её взаимодействия 
с файловой системой важно не только наличие инструментов прогноза, но и практический опыт их применения на реальных 
данных. Проведённая работа подтверждает, что даже простые прогнозные модели позволяют заранее выявить уязвимости 
и тем самым существенно сократить как время на внедрение новых решений, так и затраты на их эксплуатацию.

Таким образом, поставленные в работе задачи можно считать успешно решёнными, а результаты – полезными для последующего 
применения и развития как в рамках исследовательских проектов, так и в промышленной эксплуатации сложных баз данных.
