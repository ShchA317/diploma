\section{Тестирование и апробация разработанного решения}

\subsection{Методика апробации и валидирования разрабатываемого средства}

В целях всесторонней оценки корректности и практической применимости разработанного программного средства 
для оценки планируемой нагрузки на систему ввода-вывода СУБД PostgreSQL была реализована процедура тестирования, 
состоящая из нескольких этапов, включающая автоматизированный сбор статистики ввода-вывода на уровне самой СУБД, 
операционной системы, а также сопоставление полученных результатов с прогнозными значениями, 
рассчитываемыми предлагаемой программой. Для автоматизации получения метрик на выделенном сервере был применён 
специально разработанный скрипт (листинг приведён в приложении), обеспечивающий последовательное выполнение следующих действий:

\begin{itemize} 
    \item выбор тестового сценария из подготовленных примеров; 
    \item автоматизированная подготовка данных в тестовой базе (выполнение DDL-операций и наполнение содержимым); 
    \item запуск серии запросов к PostgreSQL с параметризированной интенсивностью (RPS -- requests per second) и продолжительностью нагрузки; 
    \item сбор статистики ввода-вывода посредством штатных средств \\
        СУБД PostgreSQL (динамические представления \texttt{pg\_stat\_io}, \\
        \texttt{pg\_statio\_user\_tables}), 
        а также средствами операционной системы (\texttt{/proc/PID/io}, \texttt{iostat}); 
    \item накопление и анализ дифференциальных показателей между состояниями до и после нагрузки. 
\end{itemize}

Полученные в процессе автоматических тестовых прогонах метрики сравнивались с результатами, 
выдаваемыми предсказывающим алгоритмом, реализованным в рамках дипломного проекта. Совокупность собранных данных 
позволила осуществить сопоставление точности расчетных и фактических величин нагрузки на I/O-подсистему.

Следует отметить, что в данном разделе изложены только общие принципы и последовательность испытаний. 

Детализированное изложение указанных аспектов позволит объективно оценить эффективность и практическую значимость 
разрабатываемого программного средства в условиях разнообразных сценариев эксплуатации СУБД PostgreSQL.

\subsection{Описание тестовых примеров и сценариев}

\begin{table}[htbp]
    \centering
    \captionsetup{justification=centering}
    \caption{Сравнительная характеристика сценариев тестирования PostgreSQL}
    \label{tab:scenarios_short}
    \begin{tabular}{|l|>{\raggedright}p{4.2cm}|l|l|l|l|}
        \hline
        № & Табличная структура (DDL и объём)    & RPS & Индексы & TOAST & Тип нагрузки \\
        \hline
        1 & users (500\,000), orders (1\,200\,000) & 5 & PK, FK & да & SELECT \\ \hline
        2 & sensor\_data (100\,000\,000) & 3 & PK & нет & SELECT \\ \hline
        3 & accounts (200\,000) & 1 & PK, UNIQUE & нет & SELECT \\ \hline
        4 & logs (растет с 0) & 2 & PK & да & INSERT \\ \hline
    \end{tabular}
    \vspace{0.5em}
\end{table}

\textbf{Пояснения:}
\begin{itemize}
    \item В графе ``TOAST'' указано, требуется ли для сценария механизм хранения крупногабаритных данных (TOAST), см.~\cite{postgres_toast}.
    \item ``PK''~--- первичный ключ; ``FK''~--- внешний ключ; ``UNIQUE''~--- уникальный индекс.
    \item Объёмы приведены в количестве строк таблицы согласно сценариям.
    \item Если поле типа JSONB или TEXT может содержать данные, превышающие одну страницу (8~КБ), PostgreSQL применяет TOAST~\cite{postgres_toast,postgres_docs}.
\end{itemize}

\subsection{Тестовая среда и ресурсы}

Тестирование проводилось на выделенном сервере, предоставленном одним из популярных провайдеров облачных решений. 
Система управления базами данных (СУБД) была развернута на операционной системе Ubuntu без дополнительных оптимизаций конфигурации, 
что позволило оценить её производительность в условиях стандартной настройки. 
Такой подход обеспечил объективность результатов тестирования, исключив влияние сторонних модификаций и специализированных тюнинговых параметров.

\insertlisting{Конфигурация тестового стенда \texttt{stand.yaml}}{code/stand.yaml}

В приведённом ниже фрагменте конфигурационного файла PostgreSQL представлены только те параметры, 
которые были явно заданы в стандартной поставке системы управления базами данных (СУБД). 
Остальные настройки соответствуют значениям по умолчанию, предусмотренным базовой конфигурацией. 
В ходе тестирования параметры СУБД не изменялись, за исключением случаев, когда их модификация была явно указана в условиях эксперимента.

\insertlisting{Часть конфигурации СУБД}{code/stand.yaml}

Более полный файл конфигурации PostgreSQL представлен в (см. \ref{app:postgresql_conf}), если в нем нет искомого параметра, 
то параметр имеет стандартное значение для данной версии СУБД.

\subsubsection{Определение характеристик устройства хранения данных}

Для получения объективных характеристик производительности подсистемы ввода-вывода была проведена 
серия тестов с использованием специализированного инструмента {\tt fio}. Данный инструмент позволяет 
моделировать сценарии работы с диском, приближённые к реальной нагрузке систем управления базами данных. 

Следует отметить, что облачный провайдер не предоставляет информацию о модели и технических характеристиках используемого устройства хранения данных. 
Пользователь получает лишь сведения о лимитах производительности ввода-вывода (IOPS) и типе носителя (SSD), 
что ограничивает возможности для детального анализа физических параметров диска.

В частности, для оценки параметров устройства хранения данных использовалась следующая команда:

\insertlisting{Команда тестирования диска с помощью утилиты fio}{code/fio_test.sh}

Параметры использования ключей {\tt fio} следующие:
\begin{itemize}
    \item \texttt{--randrepeat=1} --- обеспечивается воспроизводимость тестирования за счёт фиксированного генератора случайных чисел;
    \item \texttt{--ioengine=libaio} --- используется асинхронный движок ввода-вывода для максимально полного использования возможностей современной операционной системы;
    \item \texttt{--direct=1} --- операции выполняются в режиме прямого доступа, минуя кэш операционной системы;
    \item \texttt{--gtod\_reduce=1} --- минимизация накладных расходов на получение меток времени;
    \item \texttt{--name=test} --- имя задания;
    \item \texttt{--filename=test} --- путь к тестовому файлу;
    \item \texttt{--bs=4k} --- размер блока ввода-вывода составляет 4 КБ, что соответствует типичному размеру страницы в PostgreSQL;
    \item \texttt{--iodepth=64} --- глубина очереди запросов 64, что имитирует параллельную обработку нескольких запросов;
    \item \texttt{--size=1G} --- размер тестируемого файла составляет 1 ГБ;
    \item \texttt{--readwrite=randrw} --- моделируются смешанные случайные чтения и записи;
    \item \texttt{--rwmixread=75} --- 75\% операций приходится на чтение, остальные 25\% на запись;
    \item \texttt{>} \texttt{disk\_benchmark.txt} --- результаты тестирования выводятся в файл для последующего анализа.
\end{itemize}

Полученные данные были использованы для калибровки и построения модели оценки нагрузки на подсистему ввода-вывода при работе СУБД PostgreSQL.

\insertlisting{Результаты тестирования устройства ввода-вывода}{code/disk_benchmark.txt}

\subsection{Сравнение результатов предсказания с реальными замерами}

В результате работы программы-предсказателя нагрузки был получен следующий файл:

\insertlisting{Результат предсказания для example1 \texttt{example1-predict-result.yaml}}{code/results/example1-predict-result.yaml}

Согласно представленным данным, ожидаемая нагрузка на файловую систему при нулевом попадании в кэш составляет порядка 160~MB/s. 
Использование значения нулевого попадания в кэш обусловлено характером тестируемой нагрузки — 
в данном случае имитируется случайное чтение с нормально распределённым смещением относительно среднего значения, 
что минимизирует эффективность кэширования чтения.

\insertlisting{Результат замеров для example1 \texttt{example1-result.yaml}}{code/results/example1-result.txt}

Анализируя результаты замеров, можно отметить, что фактическое попадание в кэш чтения составило 424\,564 из 4\,401\,240\,677 
обращений, то есть менее 0{,}01\%, что подтверждает допустимость предположения о пренебрежимо малом влиянии кэша на итоговую нагрузку. 
При таких условиях предсказатель оценивает нагрузку максимально близко к реальной ситуации дисковых обращений.

Необходимо отметить, что заявленные характеристики используемого в эксперименте дискового устройства составляют не более 45~MB/s 
по последовательному чтению, в то время как рассчитанная программой-предсказателем нагрузка существенно превышает этот лимит. 
На практике получение подобной нагрузки для данной системы невозможно, что априори указывает на потенциальное возникновение нерасчётных 
задержек и деградации производительности. Таким образом, полученный прогноз позволяет на этапе планирования эксплуатации заблаговременно 
выявлять сценарии некорректного проектирования нагрузки на систему ввода-вывода и принимать управляющие решения на стадии внедрения.

Для подтверждения корректности прогноза была проведена экспериментальная оценка: время выполнения всей нагрузки 
(50 запросов — интенсивность 5 RPS в течение 10 секунд) зафиксировано при помощи скрипта мониторинга. 
Фактически полученное время выполнения оказалось сопоставимо с теоретически расчётным, учитывая ограничение по пропускной способности диска, 
что подтверждает адекватность прогноза, произведённого разработанным средством.

Таким образом, проведённое сравнение демонстрирует практическую ценность применения программного средства для оценки планируемой нагрузки: 
несмотря на синтетическую природу примера, подход оказывается применимым для заблаговременного предотвращения 
возникновения ситуаций перегрузки системы ввода-вывода СУБД PostgreSQL.

\subsection{Анализ точности предсказаний}

Для объективной оценки точности работы разработанного программного средства был проведён ряд экспериментов с различными сценариями 
нагрузки на систему ввода-вывода СУБД PostgreSQL. В каждом сценарии параметрически задавались типы запросов, их интенсивность, 
распределение обращений к данным, а также характер возвращаемых данных. Ключевой особенностью моделирования 
служило жёсткое ограничение — {\ul максимальная пропускная способность исследуемого дискового накопителя составляет 45~МБ/с}. 
Предсказанные значения, превышающие данный предел, аппроксимировались до максимально возможного значения с целью сохранения правдоподобия прогноза.

Результаты сравнения прогнозируемых и эмпирически замеренных значений приведены в таблице~\ref{tab:prediction_accuracy}. 
В таблице отображены прогнозные значения, скорректированные с учётом физического предела диска, а также соответствующие им реальные показатели, 
полученные при тестировании; дополнительно рассчитана относительная ошибка прогноза.

\begin{table}[H]
    \centering
    \caption{Сравнение расчётной и реальной нагрузки на систему ввода-вывода (максимальная пропускная способность 45~МБ/с)}
    \label{tab:prediction_accuracy}
    \begin{tabularx}{\textwidth}{L{2.5cm}C{5cm}C{2cm}C{4.5cm}}
        \toprule
        \textbf{Тестовый пример} & \textbf{Корректированная нагрузка, МБ/с} & \textbf{Факт, МБ/с} & \textbf{Относительная ошибка, \%} \\
        \midrule
        example1 & 160 & 208 & 30,0 \\
        example2 & 40 & 32 & 20,0 \\
        example3 & 38 & 32 & 15,8 \\
        example4 & 28 & 39 & 39,3 \\
        \bottomrule
    \end{tabularx}
\end{table}

\subsubsection{Методика приведения расчётных значений к фактическим ограничениям}

В рамках экспериментов основная задача заключалась в сопоставлении прогнозируемых нагрузок с фактическими возможностями 
оборудования — максимальная пропускная способность тестируемого диска составляла 45~МБ/с. Для этого расчётные значения, 
получаемые на этапе моделирования, сопоставлялись с эмпирическими результатами, полученными при выполнении серии однородных запросов к СУБД.

В каждом сценарии проводилась следующая процедура. Формировалась серия из $rps \times 10$ однотипных запросов, 
которые, согласно теоретической модели, должны были завершаться за 10 секунд (исходя из предполагаемой интенсивности 
и объёма обработки данных). В ходе экспериментального замера фиксировалось реальное время, затраченное на выполнение 
всей серии запросов, которое в ряде случаев превышало расчётное значение из-за ограничения пропускной способности.

Для корректировки прогноза вводился поправочный коэффициент $k$, определяемый следующим образом:
\begin{equation}
    k = \frac{t_{\text{факт}}}{t_{\text{модель}}}
\end{equation}
где $t_{\text{факт}}$~--- фактическое время исполнения серии запросов, $t_{\text{модель}} = 10$~секунд~--- ожидаемое время по модели.

Далее, с целью приведения моделируемой нагрузки к фактическим ограничениям аппаратуры, использовалась корректировка нагрузки следующим образом:
\begin{equation}
    L_{\text{скорр}} = L_{\text{расчёт}} \times k
\end{equation}
где $L_{\text{скорр}}$~--- скорректированное значение нагрузки, отражающее реальную пропускную способность с учётом аппаратных ограничений.

Таким образом, реальная нагрузка увеличивалась на поправочный коэффициент, отражающий замедление выполнения запросов из-за ограничений дисковой подсистемы. 
Для всех сценариев, в которых изначальный расчёт перегружал систему (значения превышали 45~МБ/с), 
такой подход позволил объективно привести полученные данные в соответствие с максимальными возможностями 
оборудования и обеспечить корректность сравнения расчётных и эмпирических результатов.

\subsection{Анализ ошибок и отклонений}

В результате проведённого тестирования разработанного средства оценки планируемой нагрузки на систему ввода-вывода СУБД PostgreSQL 
были выявлены существенные отклонения прогнозируемых значений от реальных показателей. Данную особенность можно объяснить наличием 
множества факторов, не учтённых в модели, что является ожидаемым исходом при работе с комплексными системами ввода-вывода и многопараметрическими нагрузками.

Следует отметить, что данные нюансы и возможные источники отклонений подробно рассматривались в первых главах данной работы, 
где была обоснована методология построения модели оценки нагрузки и определены её ограничения. Такое поведение системы, 
а также отмеченные отклонения существенно не противоречат поставленным целям исследования и рассматриваются как приемлемые 
в рамках текущего этапа разработки.

Особое внимание заслуживает поведение системы в моменты максимальных нагрузок на диск. В указанные периоды наблюдалась стабильно 
высокая загрузка накопителя, сопровождавшаяся ощутимым снижением производительности. Интересно, что именно в эти моменты 
предсказательная модель демонстрировала завышенные значения планируемой нагрузки, превосходящие фактические возможности дисковой 
подсистемы. Данный феномен свидетельствует о том, что прогнозирование нагрузки может выявлять потенциальные «узкие места» в инфраструктуре 
ввода-вывода, что является важным аспектом для последующей оптимизации и масштабирования системы.

\subsection{Обсуждение ограничений текущей реализации}

Текущая версия программы прогнозирования нагрузки на диск учитывает только обращения к основным файлам таблицы, 
индексам, TOAST и сопутствующим вспомогательным файлам, основываясь на предполагаемом числе чтений и записей к ним. 
Однако реализация не учитывает целый ряд важных источников нагрузки, таких как операции UPDATE и DELETE, 
а также связанные с ними процессы вакуумирования и autovacuum. Помимо этого, в расчетах не моделируется вклад 
операций логирования (например, дополнительных обращений к WAL), влияние которых может быть заметным при интенсивной 
работе базы данных.

Ещё одним существенным ограничением является то, что модель работает с обобщенными параметрами кэширования 
(cache hit ratio) и не принимает во внимание фактическую конфигурацию буферов, показатели системы хранения 
и механизмы управления памятью PostgreSQL. В реальных условиях существенно влияют дополнительные слои кэширования 
на стороне операционной системы, особенности реализации драйверов и контроллеров, нагрузка от конкурирующих приложений, 
а также алгоритмы распределения ввода-вывода на уровне железа. Всё это может приводить к существенным расхождениям 
между расчетными и фактическими значениями нагрузки.

\subsection{Выводы по результатам апробации}

В ходе апробации программы были выявлены случаи, когда рассчитанные значения нагрузки на дисковую подсистему заметно 
отличались от фактических данных, получаемых в реальных условиях эксплуатации PostgreSQL. Наиболее заметные расхождения 
наблюдаются при интенсивных смешанных нагрузках, а также при активной работе внутренних механизмов СУБД 
(например, autovacuum), которые не учтены в текущей реализации.

Тем не менее, несмотря на эту погрешность, полученные результаты имеют практическую ценность: модель позволяет 
получить ориентировочное представление о возможной нагрузке на диск в зависимости от выбранных сценариев работы с 
данными и уровней кэширования. Использование подобных прогнозов может быть полезным на ранних стадиях проектирования 
системы, при сравнительной оценке разных вариантов размещения данных или при предварительной оценке потенциальных 
проблем с производительностью. В дальнейшем точность прогнозов можно повысить за счёт расширения модели, 
более детального учета всех механизмов работы PostgreSQL и настройки параметров согласно реальным характеристикам оборудования.
